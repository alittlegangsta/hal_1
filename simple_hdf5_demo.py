#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HDF5å¢é‡å¤„ç†ç®€åŒ–æ¼”ç¤º - è§£å†³æ ¸å¿ƒé—®é¢˜
"""

import sys
import numpy as np
import logging
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('src')

from src.hdf5_manager import HDF5DataManager, BatchProcessor
from src.data_loader import DataLoader
from src.signal_processing import SignalProcessor

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_hdf5_basic_functionality():
    """æµ‹è¯•HDF5åŸºæœ¬åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•HDF5åŸºæœ¬åŠŸèƒ½...")
    
    test_path = "data/processed/test_features.h5"
    Path("data/processed").mkdir(parents=True, exist_ok=True)
    
    # åˆ é™¤æ—§æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if Path(test_path).exists():
        Path(test_path).unlink()
    
    try:
        # 1. åˆ›å»ºHDF5ç®¡ç†å™¨
        manager = HDF5DataManager(test_path, mode='w')
        
        # 2. åˆ›å»ºæ•°æ®é›†ç»“æ„
        total_samples = 100
        manager.create_dataset_structure(
            total_samples=total_samples,
            image_shape=(127, 1024),
            vector_dim=8,
            chunk_size=50
        )
        
        # 3. åˆ›å»ºæ‰¹å¤„ç†å™¨
        batch_processor = BatchProcessor(manager, batch_size=20)
        
        # 4. ç”Ÿæˆæµ‹è¯•æ•°æ®å¹¶å†™å…¥
        logger.info("ç”Ÿæˆæµ‹è¯•æ•°æ®...")
        for i in range(total_samples):
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            image_feature = np.random.random((127, 1024)).astype(np.float32)
            vector_feature = np.random.random(8).astype(np.float32)
            label = np.random.random()
            metadata = (2850.0 + i, 7, 0, i)  # (depth, receiver_id, sector, sample_id)
            
            batch_processor.add_sample(image_feature, vector_feature, label, metadata)
            
            if (i + 1) % 20 == 0:
                logger.info(f"å·²æ·»åŠ  {i + 1} ä¸ªæ ·æœ¬")
        
        # 5. å®Œæˆå¤„ç†
        actual_samples = batch_processor.finalize()
        logger.info(f"âœ… æˆåŠŸå†™å…¥ {actual_samples} ä¸ªæ ·æœ¬")
        
        # 6. æµ‹è¯•è¯»å–
        manager.mode = 'r'
        info = manager.get_data_info()
        logger.info(f"HDF5æ–‡ä»¶ä¿¡æ¯: {info}")
        
        # è¯»å–éƒ¨åˆ†æ•°æ®
        sample_data = manager.read_batch(0, 10)
        logger.info(f"è¯»å–æµ‹è¯•: å›¾åƒ={sample_data['image_features'].shape}, å‘é‡={sample_data['vector_features'].shape}")
        
        return True
        
    except Exception as e:
        logger.error(f"HDF5æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if Path(test_path).exists():
            Path(test_path).unlink()
            logger.info("å·²æ¸…ç†æµ‹è¯•æ–‡ä»¶")

def test_real_data_processing():
    """æµ‹è¯•çœŸå®æ•°æ®å¤„ç†ï¼ˆå°è§„æ¨¡ï¼‰"""
    logger.info("ğŸ”¬ æµ‹è¯•çœŸå®æ•°æ®å¤„ç†...")
    
    try:
        # 1. åŠ è½½çœŸå®æ•°æ®
        data_loader = DataLoader()
        signal_processor = SignalProcessor()
        
        logger.info("åŠ è½½CASTå’ŒXSILMRæ•°æ®...")
        cast_data = data_loader.load_cast_data()
        xsilmr_data = data_loader.load_xsilmr_data()
        
        # 2. ç­›é€‰å°èŒƒå›´æ•°æ® (ä»…10ftèŒƒå›´æµ‹è¯•)
        test_depth_range = (2850.0, 2860.0)
        filtered_cast, filtered_xsilmr = data_loader.filter_depth_range(
            min_depth=test_depth_range[0],
            max_depth=test_depth_range[1]
        )
        
        # 3. è®¡ç®—ç»å¯¹æ·±åº¦
        filtered_xsilmr = data_loader.calculate_absolute_depths(filtered_xsilmr)
        
        logger.info(f"ç­›é€‰åæ·±åº¦ç‚¹æ•°: CAST={len(filtered_cast['Depth'])}, XSILMR={len(filtered_xsilmr[7]['Depth'])}")
        
        # 4. åˆ›å»ºHDF5æ–‡ä»¶
        test_path = "data/processed/real_test_features.h5"
        Path("data/processed").mkdir(parents=True, exist_ok=True)
        
        if Path(test_path).exists():
            Path(test_path).unlink()
        
        # ä¼°ç®—æ ·æœ¬æ•°ï¼ˆåªå¤„ç†ä¸€ä¸ªæ¥æ”¶å™¨çš„ä¸€ä¸ªæ–¹ä½ï¼‰
        n_depths = len(filtered_xsilmr[7]['Depth'])
        total_samples = n_depths  # åªå¤„ç†æ¥æ”¶å™¨7çš„æ–¹ä½A
        
        manager = HDF5DataManager(test_path, mode='w')
        manager.create_dataset_structure(
            total_samples=total_samples,
            image_shape=(127, 1024),
            vector_dim=8,
            chunk_size=50
        )
        
        batch_processor = BatchProcessor(manager, batch_size=20)
        
        # 5. å¤„ç†æ•°æ®
        receiver_id = 7
        if receiver_id in filtered_xsilmr and 'SideA' in filtered_xsilmr[receiver_id]:
            logger.info(f"å¤„ç†æ¥æ”¶å™¨ {receiver_id} çš„æ–¹ä½Aæ•°æ®...")
            
            waveforms = filtered_xsilmr[receiver_id]['SideA']  # (1024, n_depths)
            depths = filtered_xsilmr[receiver_id]['AbsoluteDepth']
            
            # åˆ›å»ºæ–¹ä½è§’çªœæ§½æ ‡ç­¾
            cast_depths = filtered_cast['Depth']
            cast_zc = filtered_cast['Zc']
            azimuth_range = (0, 45)  # æ–¹ä½Aå¯¹åº”0-45åº¦
            
            # æ–¹ä½è§’ç´¢å¼•
            start_idx = azimuth_range[0] // 2
            end_idx = azimuth_range[1] // 2
            azimuth_zc = cast_zc[start_idx:end_idx, :]
            
            # è®¡ç®—çªœæ§½æ¯”ä¾‹
            channeling_mask = azimuth_zc < 2.5
            channeling_ratios = np.mean(channeling_mask, axis=0)
            
            # æ’å€¼åˆ°XSILMRæ·±åº¦
            sector_labels = np.interp(depths, cast_depths, channeling_ratios)
            
            # å¤„ç†æ¯ä¸ªæ·±åº¦ç‚¹
            processed_count = 0
            for depth_idx in range(min(len(depths), len(sector_labels))):
                try:
                    # æå–æ³¢å½¢
                    waveform = waveforms[:, depth_idx]  # (1024,)
                    
                    # ä¿¡å·å¤„ç†
                    filtered_waveform = signal_processor.apply_highpass_filter(waveform)
                    scalogram = signal_processor.generate_scalogram(filtered_waveform)
                    physical_features = signal_processor.extract_physical_features(filtered_waveform)
                    
                    # åˆ›å»ºç‰¹å¾å‘é‡
                    vector_features = np.array([
                        physical_features['max_amplitude'],
                        physical_features['rms_amplitude'],
                        physical_features['energy'],
                        physical_features['zero_crossings'],
                        physical_features['dominant_frequency'],
                        physical_features['spectral_centroid'],
                        receiver_id,
                        0  # æ–¹ä½Açš„ç´¢å¼•
                    ], dtype=np.float32)
                    
                    # æ ‡ç­¾å’Œå…ƒæ•°æ®
                    label = sector_labels[depth_idx]
                    metadata = (depths[depth_idx], receiver_id, 0, depth_idx)
                    
                    # æ·»åŠ åˆ°æ‰¹å¤„ç†å™¨
                    batch_processor.add_sample(scalogram, vector_features, label, metadata)
                    
                    processed_count += 1
                    
                    if processed_count % 10 == 0:
                        logger.info(f"å·²å¤„ç† {processed_count} ä¸ªæ·±åº¦ç‚¹")
                        
                except Exception as e:
                    logger.warning(f"å¤„ç†æ·±åº¦ç‚¹ {depth_idx} æ—¶å‡ºé”™: {e}")
                    continue
            
            # å®Œæˆå¤„ç†
            actual_samples = batch_processor.finalize()
            logger.info(f"âœ… æˆåŠŸå¤„ç† {actual_samples} ä¸ªçœŸå®æ ·æœ¬")
            
            # æµ‹è¯•è¯»å–
            manager.mode = 'r'
            info = manager.get_data_info()
            logger.info(f"çœŸå®æ•°æ®HDF5æ–‡ä»¶ä¿¡æ¯: å¤§å°={info['file_size_mb']:.2f}MB, æ ·æœ¬æ•°={info['total_samples']}")
            
            return True
        else:
            logger.error(f"æ¥æ”¶å™¨ {receiver_id} çš„æ–¹ä½Aæ•°æ®ä¸å­˜åœ¨")
            return False
            
    except Exception as e:
        logger.error(f"çœŸå®æ•°æ®å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        test_path = "data/processed/real_test_features.h5"
        if Path(test_path).exists():
            Path(test_path).unlink()
            logger.info("å·²æ¸…ç†çœŸå®æ•°æ®æµ‹è¯•æ–‡ä»¶")

def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("="*60)
    print("ğŸ§ª HDF5å¢é‡å¤„ç†ç³»ç»Ÿæµ‹è¯•")
    print("="*60)
    
    success_count = 0
    total_tests = 2
    
    # æµ‹è¯•1: HDF5åŸºæœ¬åŠŸèƒ½
    print("\nğŸ“‹ æµ‹è¯•1: HDF5åŸºæœ¬åŠŸèƒ½")
    print("-" * 40)
    if test_hdf5_basic_functionality():
        success_count += 1
        print("âœ… HDF5åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ HDF5åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥")
    
    # æµ‹è¯•2: çœŸå®æ•°æ®å¤„ç†
    print("\nğŸ“‹ æµ‹è¯•2: çœŸå®æ•°æ®å¤„ç†")
    print("-" * 40)
    if test_real_data_processing():
        success_count += 1
        print("âœ… çœŸå®æ•°æ®å¤„ç†æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ çœŸå®æ•°æ®å¤„ç†æµ‹è¯•å¤±è´¥")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {success_count}/{total_tests} é€šè¿‡")
    if success_count == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼HDF5å¢é‡å¤„ç†ç³»ç»Ÿå·¥ä½œæ­£å¸¸")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤é—®é¢˜")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 